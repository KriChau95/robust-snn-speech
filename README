This project trains and evaluates a spiking neural network (SNN) for binary keyword classification on the Google Speech Commands dataset using spike-train inputs generated by Speech2Spikes and neuron dynamics from snnTorch. Our study and data analysis revolved around the two words "cat" and "dog", but any of the six words in the "speech_commands" folders can be used. The data we used is from this source: https://www.kaggle.com/datasets/neehakurelli/google-speech-commands. You can create the cat and dog folders in the speech_commands folder and then download and place the .wav files form the link into the appropriate folders. The workflow is: augment the raw audio (white noise and pitch shifting), convert .wav files into spike-train representations saved as NumPy arrays, train an SNN on clean spikes or on clean + augmented spikes, and then test a trained checkpoint on clean, white-noise, or pitched spike datasets.

To install, create a Python environment and install the required packages: numpy, torch/torchaudio, snntorch, speech2spikes, librosa, soundfile, matplotlib, and tqdm. The code expects a Speech Commandsâ€“style folder layout where each class is a subfolder containing .wav files. All necesary files should exist in the final code submission, so no changes are needed.

To run the pipeline, first generate augmented audio by running python noise.py, which creates new datasets for white-noise and pitched audio. Next, convert audio to spikes by running python preprocess.py for clean data, python preprocess_distorted.py for white-noise data, and python preprocess_pitch.py for pitched data; these scripts are located in the preprocessing folder, and they write spike arrays and labels into their respective *_processed_spike_data/ folders. Then, train a model using python snn_binary_rate.py (clean only), python snn_binary_rate_wn.py (clean + white-noise combined), or python snn_binary_rate_pitch.py (clean + pitched combined), which will save a .pth checkpoint. These files are located in the snn folder. Running these files will also output each epoch ran and their respective training/test loss and accuracy. Finally, evaluate a baseline clean-trained checkpoint with python test_og_og.py (clean spikes), python test_og_wn.py (white-noise spikes), or python test_og_pitch.py (pitched spikes); each test script reports accuracy and is also located in the snn folder. Similar approach used for baseline ANN for comparison against the SNNs.